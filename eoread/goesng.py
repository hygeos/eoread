#!/usr/bin/env python3
# -*- coding: utf-8 -*-


from datetime import datetime
from eoread.common import DataArray_from_array, Repeat
from dateutil import parser
import numpy as np
from eoread.process import map_blocks
from pathlib import Path
from eoread.hdf4 import load_hdf4
from eoread import eo
import xarray as xr
from eoread.naming import naming, flags
import pysolar.solar as pysol
from dask.array import map_blocks

config = {
    'auxfile': 'ANCILLARY/GOESNG-0750.1km.hdf',
}


def Level1_GOESNG(file_1km,
                  auxfile=None,
                  convert_auxfile=True,
                  cloudmask=False,
                  chunksize=1000):
    '''
    Load GOES-NG (at 1km) product as xarray Dataset

    Arguments:
        file_1km: file at 1km
            (ex: Emultic1kmNC4_goes16_201808101100.nc)
        auxfile: path to angles file (default: config['auxfile'])
        cloudmask: whether to include the cloud mask
    '''
    ds = xr.Dataset()

    assert 'Emultic1kmNC4' in str(file_1km)
    file_500m = Path(str(file_1km).replace('Emultic1kmNC4', 'Emultic500mNC4'))
    assert Path(file_1km).exists()
    assert file_500m.exists()

    # Load 1km data
    ds_1km = xr.open_dataset(file_1km, chunks=chunksize)
    ds['VIS_004'] = ds_1km['VIS_004']
    ds['VIS_008'] = ds_1km['VIS_008']
    ds['VIS_016'] = ds_1km['VIS_016']
    ds.attrs.update(ds_1km.attrs)

    # Load 500m data
    ds_500m = xr.open_dataset(file_500m, chunks=chunksize*2)
    # downsample
    arr_resampled = 0.
    for i in [0, 1]:
        for j in [0, 1]:
            arr_resampled += ds_500m.VIS_006.isel(
                nx500m=slice(i, None, 2),
                ny500m=slice(j, None, 2))
    ds['VIS_006'] = arr_resampled/4.

    # load auxiliary file
    if auxfile is None:
        auxfile = Path(config['auxfile'])

    if convert_auxfile:
        # convert hdf4 file to netcdf
        # or use the already converted file
        ncfile = auxfile.parent/(auxfile.name.replace('.hdf', '.nc'))
        if not ncfile.exists():
            print(f'Converting {auxfile} => {ncfile}...')
            h4 = load_hdf4(auxfile, chunks=-1)
            h4.attrs['description'] = f'This file has been generated by eoread.goesng on {datetime.now()}'
            eo.to_netcdf(h4, filename=ncfile)
        aux = xr.open_dataset(ncfile, chunks=chunksize)
    else:
        # use load_hdf4 reader, which is slow for partial access
        assert auxfile.exists(), f'{auxfile} does not exist'
        aux = load_hdf4(auxfile)
    ds[naming.lat] = aux['Latitude']
    ds[naming.lon] = aux['Longitude']
    ds[naming.vza] = aux['View_Zenith']
    ds[naming.vaa] = aux['View_Azimuth']
    ds['Pixel_Area_Size'] = aux['Pixel_Area_Size']

    ds = ds.rename(
        Nlin=naming.rows,
        ny1km=naming.rows,
        Ncol=naming.columns,
        nx1km=naming.columns,
        ny500m=naming.rows,
        nx500m=naming.columns,
        )

    ds[naming.Rtoa] = xr.concat(
        [ds['VIS_004'], ds['VIS_006'], ds['VIS_008'], ds['VIS_016']],
        dim=naming.bands,
    )/100.

    # https://www.star.nesdis.noaa.gov/goesr/docs/ATBD/Imagery.pdf
    bands = [470, 640, 865, 1610]
    ds = ds.assign_coords(bands=bands)

    ds[naming.wav] = xr.DataArray(
        np.array(bands, dtype='float32'),
        dims=(naming.bands))

    # date/time
    dstart = parser.parse(ds.attrs['time_coverage_start'])
    dend = parser.parse(ds.attrs['time_coverage_end'])
    dt = dstart + (dend - dstart)/2
    ds.attrs[naming.datetime] = dt.isoformat()

    # solar angles
    def calc_sza(lat, lon):
        return 90. - pysol.get_altitude(
            lat, lon, dt,
            pressure=0.0,
            elevation=0.0,
        )

    def calc_saa(lat, lon):
        return pysol.get_azimuth(lat, lon, dt)

    ds[naming.sza] = (
        ds.latitude.dims,
        map_blocks(calc_sza, ds.latitude.data, ds.longitude.data),
    )

    ds[naming.saa] = (
        ds.latitude.dims,
        map_blocks(calc_saa, ds.latitude.data, ds.longitude.data),
    )
    
    # rechunk
    ds = ds.chunk(chunksize)

    # Attributes
    ds.attrs['auxfile'] = str(auxfile)

    # Other
    ds.attrs[naming.platform] = 'GOES-NG'
    ds.attrs[naming.sensor] = 'ABI'
    ds.attrs[naming.product_name] = Path(file_1km).name.replace('.nc', '')
    ds.attrs[naming.input_directory] = str(Path(file_1km).parent)

    ds[naming.flags] = xr.zeros_like(
        ds.vza,
        dtype=naming.flags_dtype)
    
    if cloudmask:
        dt_ = datetime.strptime(Path(file_1km).name.split('_')[-1][:-3], '%Y%m%d%H%M')
        cmaskfile = Path(file_1km).parent/datetime.strftime(dt_, r'S_NWC_CMA_GOES16_globeE-NR_%Y%m%dT%H%M%SZ.nc')
        assert cmaskfile.exists(), str(cmaskfile)
        
        cm = xr.open_dataset(cmaskfile, chunks=chunksize)

        cma = DataArray_from_array(
            Repeat(cm.cma, (2, 2)),
            ('ny', 'nx'),
            chunksize,
        ).rename(
            ny=naming.rows,
            nx=naming.columns,
        )

        eo.raiseflag(ds[naming.flags], 'CLOUD_BASE', flags['CLOUD_BASE'], cma)

    return ds
    

